# Transformers Recipe
A quick recipe to learn all about Transformers

Transformers have accelerated the development of new techniques and models for natural language processing (NLP) tasks. While it has mostly been used for NLP tasks, it is now seeing heavy adoption to address computer vision tasks. That makes it a very important technique to understand and be able to apply.

I am aware that a lot of machine learning and NLP students and practitioners are keen on learning about transformers. Therefore, I am motivated to prepare and maintain a recipe of resources and study materials to help students learn about the world of Transformers.

To begin with, in this post (originally a Twitter thread), I have prepared a few links to materials that I used to better understand and implement transformer models from scratch.

The reason for this post is so that I have an easy way to continue to update the study material.

## ğŸ§  High-level Introduction
First, try to get a very high-level introduction about transformers. Some references worth looking at:

ğŸ”— https://theaisummer.com/transformer/

ğŸ”— https://hannes-stark.com/assets/transformer_survey.pdf

ğŸ”— https://youtu.be/8zAP2qWAsKg

## ğŸ¨ The Illustrated Transformer
Jay Alammar's illustrated explanations are exceptional. Once you get that high-level understanding of transformers, you can jump into this popular illustrated explanation of transformers:

ğŸ”— http://jalammar.github.io/illustrated-transformer/

## ğŸ”– Technical Summary
At this point, you may be looking for a technical summary and overview of transformers. Lilian Weng's blog posts are a gem and provide concise technical explanations/summaries:

ğŸ”— https://lilianweng.github.io/lil-log/2020/04/07/the-transformer-family.html

## ğŸ‘©ğŸ¼â€ğŸ’» Implementation
After the theory, it's important to test the knowledge. I typically prefer to understand things in more detail so I prefer to implement algorithms from scratch. For implementing transformers, I mainly relied on this tutorial:

ğŸ”— https://nlp.seas.harvard.edu/2018/04/03/attention.html

## ğŸ“„ Attention Is All You Need
This paper by Vaswani et al. introduced the Transformer architecture. Read it after you have a high-level understanding and want to get into the details. Pay attention to other references in the paper for diving deep.

ğŸ”— https://arxiv.org/pdf/1706.03762v5.pdf

## ğŸ‘©ğŸ¼â€ğŸ’» Applying Transformers
After some time studying and understanding the theory behind transformers, you may be interested in applying them to different NLP projects or research. At this time, your best bet is the Transformers library by HuggingFace.

ğŸ”— https://github.com/huggingface/transformers

Feel free to suggest study material. In the next update, I am looking to add a more comprehensive collection of Transformer applications and papers. In addition, a code implementation for easy experimentation is coming as well.

I try to regularly maintain this guide. To get regular updates on new ML and NLP resources, follow me on Twitter.
